#include <stdio.h>
#include <stdlib.h>
#include <math.h>

// Simple nn that can learn the xor function

// Sigmoid functions from math
double sigmoid(double x) { return 1 / (1 + exp(-x)); }
double dSigmoid(double x) { return x * (1-x); }

// Initialize weights to a random value
double init_weights() { return ((double)rand()) / ((double)RAND_MAX); }

// Shuffle data
void shuffle(int *array, size_t n) {
	if (n > 1) {
		size_t i;
		for (i = 0; i < n - 1; i++) {
			size_t j = i + rand() / (RAND_MAX / (n - i) + 1);
			int t = array[j];
			array[j] = array[i];
			array[i] = t;
		}
	}
}

#define numInputs 2
#define numHiddenNodes 10
#define numOutputs 1
#define numTrainingSets 4
#define numEpoch 10000

int main(void) {
	
	// Learning rate
	const double lr = 0.5f;
	
	// Layers
	double hiddenLayer[numHiddenNodes];
	double outputLayer[numOutputs];
	
	// Biases
	double hiddenLayerBias[numHiddenNodes];
	double outputLayerBias[numOutputs];

	// Weights
	double hiddenWeights[numInputs][numHiddenNodes];
	double outputWeights[numInputs][numOutputs];

	// Training data
	double training_inputs[numTrainingSets][numInputs] = {  {1.0f, 1.0f},
															{1.0f, 0.0f},
															{0.0f, 1.0f},
		  													{0.0f, 0.0f}}; 
	double training_outputs[numTrainingSets][numOutputs] = {{1.0f},
															{0.0f},
															{1.0f},
		  													{1.0f}};

	// Intialize input weights
	for (int i = 0; i < numInputs; i++) {
		for (int j = 0; j < numHiddenNodes; j++) {
			hiddenWeights[i][j] = init_weights();
		}
	}

	// Initalize hidden weights
	for (int i = 0; i < numHiddenNodes; i++) {
		for (int j = 0; j < numOutputs; j++) {
			outputWeights[i][j] = init_weights();
		}
	}

	// Initialize output bias
	for (int i = 0; i < numOutputs; i++) {
		outputLayerBias[i] = init_weights();
	}

	// Order data
	int trainingSetOrder[] = {0, 1, 2, 3};
	
	// Train the nn for a number of epochs
	for (int epoch = 0; epoch < numEpoch; epoch++) {
		shuffle(trainingSetOrder, numTrainingSets);
		for (int x = 0; x < numTrainingSets; x++) {
			int i = trainingSetOrder[x];

			// Forward Pass

			// Compute hidden layer activation
			for (int j = 0; j < numHiddenNodes; j++) {
				double activation = hiddenLayerBias[j];
				for (int k = 0; k < numInputs; k++) {
					activation += training_inputs[i][k] * hiddenWeights[k][j];
				}
				hiddenLayer[j] = sigmoid(activation);
			}

			// Compute output layer activation
			for (int j = 0; j < numOutputs; j++) {
				double activation = outputLayerBias[j];
				for (int k = 0; k < numHiddenNodes; k++) {
					activation += hiddenLayer[k] * outputWeights[k][j];
				}
				outputLayer[j] = sigmoid(activation);
			}

			printf("Input: %g - %g, Output: %g, Expected Output: %g\n", training_inputs[i][0], training_inputs[i][1], outputLayer[0], training_outputs[i][0]);
			
			// Back propogation
			// Computer chage in output weights
			double deltaOutput[numOutputs];
			
			for (int j = 0; j < numOutputs; j++) {
				double error = (training_outputs[i][j] - outputLayer[j]);
				deltaOutput[j] = error * dSigmoid(outputLayer[j]);
			}

			// Compute change in hidden weights
			double deltaHidden[numHiddenNodes];
			for (int j = 0; j < numHiddenNodes; j++) {
				double error = 0.0f;
				for (int k = 0; k < numOutputs; k++) {
					error += deltaOutput[k] * outputWeights[j][k];
				}
				deltaHidden[j] = error * dSigmoid(hiddenLayer[j]);
			}

			// Apply chages in output weights
			for (int j = 0; j < numOutputs; j++) {
				outputLayerBias[j] += deltaOutput[j] * lr;
				for (int k = 0; k < numHiddenNodes; k++) {
					outputWeights[k][j] += hiddenLayer[k] * deltaOutput[j] * lr;
				}
			}

			// Apply changes in hidden weights
			for (int j = 0; j < numHiddenNodes; j++) {
				hiddenLayerBias[j] += deltaHidden[j] * lr;
				for (int k = 0; k < numInputs; k++) {
					hiddenWeights[k][j] += training_inputs[i][k] * deltaHidden[j] * lr;
				}
			}
		}	
	}
	int numinputs = numInputs;
	int numoutputs = numOutputs;
	int numhiddennodes = numHiddenNodes;
	int one = 1;
	FILE *file;
	file = fopen("weights/xor.bin", "wb");
	fwrite(&numinputs, sizeof(int), 1, file);
    fwrite(&numoutputs, sizeof(int), 1, file);
    fwrite(&one, sizeof(int), 1, file);
    for(int i = 0; i < 1; i++) {
        fwrite(&numhiddennodes, sizeof(int), 1, file);
    }

    // Writes first layer bias and input weights
    for (int n = 0; n < numHiddenNodes; n++) {
        fwrite(&hiddenLayerBias[n], sizeof(double), 1, file); // Write bias
        for (int i = 0; i < numInputs; i++) {
            fwrite(&hiddenWeights[i][n], sizeof(double), 1, file);
        }
    }

    // output biases and last hidden layer weights
    for (int n = 0; n < numOutputs; n++) {
        fwrite(&outputLayerBias[n], sizeof(double), 1, file);
        for (int i = 0; i < numHiddenNodes; i++) {
            fwrite(&outputWeights[i][n], sizeof(double), 1, file);
        }
    }
	return 0;
}
